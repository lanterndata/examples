{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!python -m pip install pgpq\n",
    "!python -m pip install psycopg\n",
    "!python -m pip install SQLAlchemy\n",
    "!pip install pinecone-datasets\n",
    "# make sure to authenticate to gcp before reading parquet from there via pandas.read_parquet!!\n",
    "!pip install psycopg2-binary\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone_datasets import list_datasets, load_dataset, Dataset\n",
    "list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg\n",
    "import lib\n",
    "from importlib import reload\n",
    "from sqlalchemy import create_engine\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "reload(lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = \"postgresql://postgres:postgres@localhost:6666\"\n",
    "# lib.recreate_tables(conn_string)\n",
    "lib.create_extensions(conn_string)\n",
    "conn = psycopg.connect(conn_string)\n",
    "engine = create_engine(conn_string, echo=True)\n",
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfcc_data = lib.get_yfcc_data(dataset='10M') # 100K\n",
    "yfcc_data_queries = lib.get_yfcc_data(queries=True, dataset='10M') # 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map blob column to jsonb\n",
    "lib.df2pg(conn_string, yfcc_data)\n",
    "# if the DB instance is small, tthe above may fail with OOM at _transform_metadata step. In that case you can specifically rerun that step\n",
    "# lib._transform_metadata(conn_string)\n",
    "lib.df2pg(conn_string, yfcc_data_queries, queries=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT id, metadata_tags, blob FROM yfcc_passages LIMIT 1\")\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_sql('select * from yfcc_passages limit 10', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('select * from yfcc_passages limit 10', con=engine)\n",
    "# select only rows from the pg table that have blob->selectibity < 10\n",
    "df = pd.read_sql(\"select blob->>'selectivity', * from yfcc_queries where blob->>'selectivity'> \\'10\\' limit 10\", con=engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT id, embedding FROM yfcc_10m WHERE metadata @> '{\"tags\": [\"108757\"]}' ORDER BY embedding <-> '[...]' LIMIT 10;\n",
    "# run this query with engine ORDER BY vector <-> '{0.1, 0.2, 0.3}'\n",
    "# get all rows where metadata array has more than one element\n",
    "# df = pd.read_sql(\"\"\"SELECT id, metadata FROM yfcc_data WHERE array_length(metadata, 1) > 1 ORDER BY id LIMIT 100 \"\"\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select count(indexname) from pg_indexes where indexname LIKE 'hnsw_filtered%' ;\n",
    "\n",
    "\n",
    "explain (analyze, buffers)\n",
    "                        SELECT id,\n",
    "                    vector::real[] <-> ARRAY[170.0, 130.0, 121.0, 95.0, 129.0, 105.0, 135.0, 114.0, 150.0, 110.0, 199.0, 126.0, 129.0, 168.0, 108.0, 142.0, 104.0, 114.0, 118.0, 98.0, 141.0, 131.0, 108.0, 147.0, 103.0, 125.0, 128.0, 106.0, 69.0, 141.0, 132.0, 103.0, 92.0, 114.0, 104.0, 163.0, 118.0, 127.0, 121.0, 89.0, 115.0, 163.0, 80.0, 82.0, 86.0, 156.0, 150.0, 89.0, 134.0, 155.0, 139.0, 149.0, 143.0, 125.0, 126.0, 165.0, 151.0, 135.0, 98.0, 131.0, 166.0, 99.0, 149.0, 155.0, 110.0, 135.0, 123.0, 153.0, 122.0, 136.0, 198.0, 116.0, 103.0, 106.0, 141.0, 98.0, 168.0, 135.0, 130.0, 155.0, 143.0, 126.0, 133.0, 116.0, 135.0, 106.0, 120.0, 110.0, 171.0, 172.0, 132.0, 152.0, 86.0, 100.0, 111.0, 132.0, 110.0, 138.0, 122.0, 78.0, 109.0, 133.0, 140.0, 154.0, 160.0, 103.0, 154.0, 118.0, 91.0, 141.0, 132.0, 90.0, 108.0, 123.0, 135.0, 120.0, 91.0, 118.0, 109.0, 131.0, 126.0, 76.0, 122.0, 104.0, 158.0, 147.0, 110.0, 123.0, 141.0, 133.0, 120.0, 136.0, 148.0, 144.0, 101.0, 146.0, 138.0, 150.0, 121.0, 145.0, 132.0, 111.0, 141.0, 81.0, 135.0, 143.0, 140.0, 83.0, 107.0, 127.0, 146.0, 133.0, 93.0, 140.0, 102.0, 95.0, 147.0, 110.0, 130.0, 121.0, 158.0, 179.0, 142.0, 125.0, 97.0, 81.0, 110.0, 128.0, 159.0, 123.0, 163.0, 110.0, 125.0, 100.0, 150.0, 131.0, 147.0, 127.0, 150.0, 161.0, 157.0, 175.0, 138.0, 154.0, 174.0, 124.0, 148.0, 118.0, 169.0, 175.0, 156.0, 124.0]::real[] as dist\n",
    "                FROM yfcc_passages\n",
    "                WHERE\n",
    "                    metadata_tags @> ARRAY[12] AND metadata_tags @> ARRAY[11]\n",
    "                ORDER BY dist\n",
    "                LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create partial indexes\n",
    "\n",
    "\n",
    "\n",
    "# UPDATE yfcc_passages SET vector =  (\n",
    "#   SELECT array_agg((element - 128)/ 100.0)\n",
    "#   FROM unnest(vector) AS t(element)\n",
    "# );\n",
    "# UPDATE yfcc_queries SET vector =  (\n",
    "#   SELECT array_agg((element - 128)/ 100.0)\n",
    "#   FROM unnest(vector) AS t(element)\n",
    "# );\n",
    "\n",
    "\n",
    "with psycopg.connect(conn_string) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "    DROP FUNCTION IF EXISTS create_index_statements_for_popular_tags();\n",
    "    DROP FUNCTION IF EXISTS create_index_statements_for_popular_tags(index_threshhold INTEGER);\n",
    "    CREATE OR REPLACE FUNCTION create_index_statements_for_popular_tags(index_threshhold INTEGER DEFAULT 10000)\n",
    "    RETURNS TABLE(index_command TEXT) AS\n",
    "    $$\n",
    "    DECLARE\n",
    "        tag_record RECORD;\n",
    "    BEGIN\n",
    "        FOR tag_record IN\n",
    "            SELECT tag\n",
    "            FROM (\n",
    "                SELECT unnest(metadata_tags) AS tag\n",
    "                FROM yfcc_passages\n",
    "            ) AS tags\n",
    "            GROUP BY tag\n",
    "            HAVING COUNT(*) > index_threshhold\n",
    "            ORDER BY COUNT(*) DESC\n",
    "        LOOP\n",
    "            index_command := format('CREATE INDEX IF NOT EXISTS hnsw_filtered_%s ON yfcc_passages USING lantern_hnsw(vector) WITH (quant_bits = 8) WHERE metadata_tags @> ARRAY[%s];', tag_record.tag, tag_record.tag);\n",
    "            RETURN NEXT;\n",
    "        END LOOP;\n",
    "    END;\n",
    "    $$ LANGUAGE plpgsql;\n",
    "                    \"\"\")\n",
    "    # for s in create_index_statements:\n",
    "    #     print(\"running\", s)\n",
    "    #     cursor.execute(s[0])\n",
    "# done in 792m 11.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(conn_string) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        create_index_statements = cursor.execute(\"select * from create_index_statements_for_popular_tags();\").fetchall()\n",
    "create_index_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES=40\n",
    "print(\"creating\", len(create_index_statements), \"partial indexes\")\n",
    "\n",
    "# for i, s in enumerate(create_index_statements):\n",
    "    # start NUM_CORES processes, create a connection for each and execute one statement from the list\n",
    "from multiprocessing import Pool\n",
    "def create_index(s):\n",
    "    s = s[0]\n",
    "    print(f\"running {s}\")\n",
    "\n",
    "    with psycopg.connect(conn_string) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(s)\n",
    "            \n",
    "\n",
    "with Pool(NUM_CORES) as p:\n",
    "    p.map(create_index, create_index_statements, chunksize=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prewarm everything\n",
    "\n",
    "with psycopg.connect(conn_string) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        print(\"prewarm the base table\")\n",
    "        # prewarming the base relation first, since this has lowest priority\n",
    "        # and it is ok if this gets evicted later to make space for the rest\n",
    "        cursor.execute(\"SELECT pg_prewarm('yfcc_passages')\")    \n",
    "        \n",
    "        print(\"prewarm all partial indexes\")\n",
    "        cursor.execute(\"\"\"\n",
    "SELECT pg_prewarm(i.relname::text)\n",
    "FROM pg_class t\n",
    "JOIN pg_index ix ON t.oid = ix.indrelid\n",
    "JOIN pg_class i ON i.oid = ix.indexrelid\n",
    "JOIN pg_am a ON i.relam = a.oid\n",
    "JOIN pg_namespace n ON n.oid = i.relnamespace\n",
    "WHERE a.amname = 'lantern_hnsw';\n",
    "                       \"\"\")\n",
    "        \n",
    "        print(\"prewarm pk and GIN indexes on yfcc_passages\")\n",
    "        cursor.execute(\"\"\"\n",
    "SELECT i.relname, pg_prewarm(i.relname::text)\n",
    "FROM pg_class t\n",
    "JOIN pg_index ix ON t.oid = ix.indrelid\n",
    "JOIN pg_class i ON i.oid = ix.indexrelid\n",
    "JOIN pg_am a ON i.relam = a.oid\n",
    "JOIN pg_namespace n ON n.oid = i.relnamespace\n",
    "WHERE (a.amname = 'gin' OR a.amname = 'btree') AND t.relname = 'yfcc_passages';\n",
    "                       \"\"\")\n",
    "\n",
    "        \n",
    "        \n",
    "        print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(lib)\n",
    "# for use_pgvector in [True, False]:\n",
    "for use_pgvector in [False]:\n",
    "\n",
    "    recalls, latencies, stats = lib.run_experiment(conn_string, 900, offset=2000, pgvector=use_pgvector, explain=False)\n",
    "    plt.hist(latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.vector_search(conn_string,  q_vector_id=21, explain = True, materialize_first=True, return_recall=True, reuse_conn=True, pgvector=False, prefilter_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(lib)\n",
    "# lib.vector_search(conn_string, [3432], explain = False)\n",
    "# lib.create_index(conn_string)\n",
    "res = lib.bulk_vector_search(conn_string, 3000,k=10, return_recall=True, explain=False)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if recall is none, means near_ids and near_dists are none, means no results were found\n",
    "overall_recall = sum([1 if a.recall is None else a.recall for a in res])/len(res)\n",
    "tiebreak_affected = [a for a in res if a.recall and int(a.recall) < 1  ]\n",
    "# note: even with 100% accurate scan, recall is < 1, since there are 4 rows which have equal distance to 10th and 11th result\n",
    "# and there is no stable tie breaking\n",
    "print(overall_recall, len(tiebreak_affected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"select * from yfcc_queries where (blob->'selectivity')::integer > 10 \", con=engine)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
