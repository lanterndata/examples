{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Duplicate Reviews Via Semantic Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this walkthrough we will use vector embeddings to find duplicate or similar items in a movie review dataset.\n",
    "The same approach can be used to group similar photos in your photo collection, automatically categorize data, etc.\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Get the data\n",
    "2. Setup Lantern (on top of self-hosted postgres, or in Lantern Cloud)\n",
    "3. Upload the data into Lantern\n",
    "4. Generate embeddings (__automated in Lantern Cloud!__)\n",
    "5. Create a vector index (__40x faster in Lantern Cloud!__)\n",
    "6. Query the database to find similar reviews\n",
    "    1. Brute Force - no vector index (takes ~1.5 hour)\n",
    "    2. Vector Index + Code (takes ~20 minutes)\n",
    "    3.  __Vector Index + SQL JOIN (takes ~40 seconds!)__\n",
    "    \n",
    "7. Bonus! Evaluate the quality of our approximate vector index\n",
    "8. Bonus! Flag Identical Reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install datasets sentence_transformers tqdm pandas> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use imdb movie review dataset from [huggingface](https://huggingface.co/datasets/imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/ngalstyan/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from datasets import load_dataset\n",
    "from psycopg2 import extras\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "data = load_dataset(\"imdb\", split=\"train\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Setup Lantern\n",
    "You will need access to a Lantern database to follow through this tutorial. \n",
    "\n",
    "You can get one with 3 clicks at [Lantern Cloud](https://lantern.dev), or can set up Lantern on your own environment ([docs](https://docs.lantern.dev/get-started/install-from-binaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "import psycopg2\n",
    "LANTERN_URL=\"PUT YOUR LANTERN URL HERE\"\n",
    "if not LANTERN_URL.startswith(\"postgres:\"):\n",
    "    LANTERN_URL=input(\"Please enter your Lantern URL:\")\n",
    "# Change the database URL to yours\n",
    "def connect_db():\n",
    "    return psycopg2.connect(LANTERN_URL)\n",
    "global_conn = connect_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload the data into Lantern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a table for our movie review dataset with the following schema:\n",
    "```sql\n",
    "CREATE TABLE imdb_reviews_new1 (\n",
    "    id SERIAL PRIMARY KEY, \n",
    "    imdb_id int NOT NULL UNIQUE, \n",
    "    review text, \n",
    "    positive_review bool)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's upload the data to our database so we can start running queries against it.\n",
    "Note that we are using [`psycopg2.extras.execute_values`](https://www.psycopg.org/docs/extras.html#psycopg2.extras.execute_values) to handle batch uploading for us behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "def setup_table():\n",
    "    with global_conn.cursor() as cur:\n",
    "        #cur.execute(\"abort;CREATE EXTENSION IF NOT EXISTS lantern\")\n",
    "        #cur.execute(\"DROP TABLE IF EXISTS imdb_reviews_new111\")\n",
    "        cur.execute(\"\"\"\n",
    "CREATE TABLE imdb_reviews (\n",
    "  id SERIAL PRIMARY KEY,\n",
    "  imdb_id int NOT NULL UNIQUE,\n",
    "  review text,\n",
    "  positive_review bool\n",
    ");\"\"\")\n",
    "        global_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_values(conn, values, batch_size=400, logging = True):\n",
    "    start = time.time()\n",
    "    with conn.cursor() as cur:\n",
    "        batch_review = values[\"text\"]\n",
    "        batch_sentiment = values[\"label\"]\n",
    "        id_range = range(len(values[\"text\"]))\n",
    "        \n",
    "        batch = list(zip(id_range,batch_review, batch_sentiment))\n",
    "        batch = [(e[0], e[1], e[2] == 1) for e in batch]\n",
    "        psycopg2.extras.execute_values(cur, f\"INSERT INTO imdb_reviews_new111 (imdb_id,review, positive_review) VALUES %s;\", batch,\n",
    "                                      template=None, page_size=batch_size)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_table()\n",
    "insert_values(global_conn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is just a sanity check that imdb_ids in the postgres table correspond to our array indexes in this notebook\n",
    "with global_conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT * from imdb_reviews_new111 where imdb_id = 1;\")\n",
    "    print(cur.fetchall()[0][2] == data[\"text\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate embeddings\n",
    "At this point we have all our data in our Lantern database. \n",
    "We can now go see some summary of our table in the Lantern dashboard.\n",
    "\n",
    "More importantly, we can generate embeddings through various models, add them as additional columns to our table, and create vector indexes on them through the dashboard.\n",
    "Lantern runs these operations on dedicated, workload-optimized servers, avoiding the extra load on the database instance.\n",
    "This makes sure that your database will be available with its full capacity to answer your production queries, while very compute-heavy operations are carried out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO:: screenshots from cloud?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once embedding generation and index creation fish successfully, we can see the additional columns on our table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               column_name                 data_type               is_nullable\n",
      "\n",
      "                        id                   integer                        NO\n",
      "                   imdb_id                   integer                        NO\n",
      "           positive_review                   boolean                       YES\n",
      "          review_embedding                     ARRAY                       YES\n",
      "                    review                      text                       YES\n"
     ]
    }
   ],
   "source": [
    "with global_conn.cursor() as cur:\n",
    "    form = \"{:>26}\" * 3\n",
    "    cur.execute(\"SELECT column_name, data_type, is_nullable FROM information_schema.columns WHERE table_name = 'imdb_reviews_new111';\")\n",
    "    print(form.format(\"column_name\",\"data_type\",\"is_nullable\"))\n",
    "    print()\n",
    "    for r in cur.fetchall():\n",
    "        # .join([\"%s\",\"%s\",\"%s\"])\n",
    "        print(form.format(*r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider 3 approaches for solving the problem\n",
    "1. No index, full scan of the table\n",
    "2. Lantern index + python loop to aggregate results\n",
    "3. Single JOIN query to get our answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a vector index\n",
    "\n",
    "We can again use the Lantern dashboard to create a vector index on the embedding column Lantern created for us.\n",
    "Note that to create the vector index we could use the more familiar `CREATE INDEX` statement as below:\n",
    "```python\n",
    "with global_conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE INDEX lantern_demo_idx ON lantern_demo \n",
    "    USING hnsw(vec dist_cos_ops) \n",
    "    WITH (m=32, ef_construction=128, dim=384, ef=64)\"\"\")\n",
    "```\n",
    "\n",
    "But vector index creation is an expensive operation - doing it inside the database will \n",
    "    - Take longer \n",
    "    - slow down database queries for the duration of index generation\n",
    "\n",
    "Index creation done in Lantern Dashboard happens on a separate dedicated server. The resulting index is then copied over into our database and tied to postgres, as if it was created via `CREATE INDEX`.\n",
    "This saves time and database resources! It also allows for faster iteration and index parameter tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (A. and B.) Query the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is necessary for approaches (1) and (2) only, since embedding querying happens in python\n",
    "all_embeds = None\n",
    "with global_conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT imdb_id, review_embedding from imdb_reviews_new111;\")\n",
    "    all_embeds = cur.fetchall() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_similar_foreach(all_embeds, use_index=True):\n",
    "    THRESHHOLD=0.07\n",
    "    # Load the next row from the dataset\n",
    "    dist_calculation_format = \"%s <-> review_embedding\"\n",
    "    if not use_index:\n",
    "        dist_calculation_format = \"cos_dist(%s, review_embedding)\"\n",
    "\n",
    "    with global_conn.cursor() as cur:\n",
    "\n",
    "        for imdb_id, embedding in tqdm(all_embeds):\n",
    "                \n",
    "            cur.execute(f\"SELECT cos_dist(%s, review_embedding) as dist, imdb_id from imdb_reviews_new111 order by {dist_calculation_format} limit 2;\", \n",
    "                        (embedding,embedding))\n",
    "            res = cur.fetchall()\n",
    "\n",
    "\n",
    "            for r in res:\n",
    "                dist, found_id = r\n",
    "                if found_id == imdb_id:\n",
    "                    continue\n",
    "                if dist < THRESHHOLD:\n",
    "                    print(f\"found similar! (distance={dist})\")\n",
    "                    query_txt = data[\"text\"][imdb_id]\n",
    "                    print(f\"Query({imdb_id}): {query_txt}\")\n",
    "                    found_txt = data[\"text\"][found_id]\n",
    "                    print(f\"Found({found_id}): {found_txt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 6.A: Do not use the vector index: (WIll take ~ 1.5 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d4d4f1fc314c9ca8485b8eae649df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar! (distance=0.063269675)\n",
      "Query(7694): This really is one of the worst movies ever made. I consider myself a HUGE zombie film fan and usually tolerate bad acting, lame \"special effects\" a dumb story and whatever you may encounter in second rate movies, AS LONG as the film has a good atmosphere/story/suspension or whatever to offer. This one has basically no positive aspect to it and is third or fourth rate, maybe worse. Some friends of mine and myself made a small movie during a week´s holiday and definitely did a better job (no zombie film though).<br /><br />This flick is not even funny, not speaking of anything else. Really bad and redundant special effects, zombies that look like normal people (except for a white additional skin pulled over their faces), WAY TO MUCH fake blood (I like realism a lot, the combination of realism and Zombie films being debatable, but the presented gore is just plain silly). The camera stays quite long with feedings scenes, it gets boring and you cannot help but wonder, why the zombies use WEAPONS (!) to kill their prey. I will not go into the details of the dubbing (others have done so). Although I am from Germany myself and am at least a bit curious about the original version, I will NOT waste more of my time with this movie.<br /><br />Keep away from it, as far as you can.\n",
      "Found(4159): This was quite possibly the worst movie I have ever seen. I watched it with a large group of friends and after it was over not a one of us understood the plot. Aside from the lack of plot, the acting was atrocious, the \"special effects\" were not so special, and the writing was absolutely horrible. The movie's only redeeming factor is that it's so incredibly bad that it's quite funny. You can't help but laugh at a zombie being run over while actors are spewing crappy dialogue. I wouldn't recommend this film to anyone looking for a good movie, but it's something that a group of friends can get together and have a good laugh about. It's now a running joke among my friends and I. 1 out of 10.\n",
      "found similar! (distance=0.066539526)\n",
      "Query(7693): This movie is god awful. Not one quality to this movie. You would think that the gore would be good but it sucks bad. The effects are worse and the acting if you can call it acting is the worst I've ever seen. This movie was obviously shot on a camcorder and runs on a budget around 500 dollars probably. If you want to watch a good Zombie movie than watch Dawn of the dead or Day of the dead. If you want to watch a good cheap shot on video Zombie movie like this but way better than watch Redneck Zombies. Please avoid this movie at all costs. It is unwatchable and pointless. You've been warned. I've got nothing else to say about this stupid movie.\n",
      "Found(1751): You wouldn't expect a movie like this to be good, and it isn't. It's a no budget, ultra violent zombie movie filmed with a bad looking hand-held camera...and it's hilarious. The actors obviously have never acted before and it shows in their terrible hilarious readings. There is no plot to be seen. The little plot I could find seemed to be that a government experiment escaped and a group of zombie seems to be terrorizing a couple families. The gore effects are actually some of the most sickening I've ever seen. It seems the gore effects people raided a butcher shop for all the body parts, and many scenes involve zombies dismembering people and eating their organs. It's a funny and sickening film, and it's about as bad as you can get in terms of any movie.<br /><br />My rating: BOMB/****. 90 mins.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-209d2f99a8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-b17bdf0172e1>\u001b[0m in \u001b[0;36mfind_similar_foreach\u001b[0;34m(all_embeds, use_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             cur.execute(f\"SELECT cos_dist(%s, review_embedding) as dist, imdb_id from imdb_reviews_new111 order by {dist_calculation_format} limit 2;\", \n\u001b[0;32m---> 13\u001b[0;31m                         (embedding,embedding))\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/encodings/utf_8.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "find_similar_foreach(all_embeds, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 6.B: Use the index but query it from python for each row: (WIll take ~ 25 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a485d7c84fa942afb4290be075c76be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar! (distance=0.063269675)\n",
      "Query(7694): This really is one of the worst movies ever made. I consider myself a HUGE zombie film fan and usually tolerate bad acting, lame \"special effects\" a dumb story and whatever you may encounter in second rate movies, AS LONG as the film has a good atmosphere/story/suspension or whatever to offer. This one has basically no positive aspect to it and is third or fourth rate, maybe worse. Some friends of mine and myself made a small movie during a week´s holiday and definitely did a better job (no zombie film though).<br /><br />This flick is not even funny, not speaking of anything else. Really bad and redundant special effects, zombies that look like normal people (except for a white additional skin pulled over their faces), WAY TO MUCH fake blood (I like realism a lot, the combination of realism and Zombie films being debatable, but the presented gore is just plain silly). The camera stays quite long with feedings scenes, it gets boring and you cannot help but wonder, why the zombies use WEAPONS (!) to kill their prey. I will not go into the details of the dubbing (others have done so). Although I am from Germany myself and am at least a bit curious about the original version, I will NOT waste more of my time with this movie.<br /><br />Keep away from it, as far as you can.\n",
      "Found(4159): This was quite possibly the worst movie I have ever seen. I watched it with a large group of friends and after it was over not a one of us understood the plot. Aside from the lack of plot, the acting was atrocious, the \"special effects\" were not so special, and the writing was absolutely horrible. The movie's only redeeming factor is that it's so incredibly bad that it's quite funny. You can't help but laugh at a zombie being run over while actors are spewing crappy dialogue. I wouldn't recommend this film to anyone looking for a good movie, but it's something that a group of friends can get together and have a good laugh about. It's now a running joke among my friends and I. 1 out of 10.\n",
      "found similar! (distance=0.066539526)\n",
      "Query(7693): This movie is god awful. Not one quality to this movie. You would think that the gore would be good but it sucks bad. The effects are worse and the acting if you can call it acting is the worst I've ever seen. This movie was obviously shot on a camcorder and runs on a budget around 500 dollars probably. If you want to watch a good Zombie movie than watch Dawn of the dead or Day of the dead. If you want to watch a good cheap shot on video Zombie movie like this but way better than watch Redneck Zombies. Please avoid this movie at all costs. It is unwatchable and pointless. You've been warned. I've got nothing else to say about this stupid movie.\n",
      "Found(1751): You wouldn't expect a movie like this to be good, and it isn't. It's a no budget, ultra violent zombie movie filmed with a bad looking hand-held camera...and it's hilarious. The actors obviously have never acted before and it shows in their terrible hilarious readings. There is no plot to be seen. The little plot I could find seemed to be that a government experiment escaped and a group of zombie seems to be terrorizing a couple families. The gore effects are actually some of the most sickening I've ever seen. It seems the gore effects people raided a butcher shop for all the body parts, and many scenes involve zombies dismembering people and eating their organs. It's a funny and sickening film, and it's about as bad as you can get in terms of any movie.<br /><br />My rating: BOMB/****. 90 mins.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-71a42051153f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-b17bdf0172e1>\u001b[0m in \u001b[0;36mfind_similar_foreach\u001b[0;34m(all_embeds, use_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             cur.execute(f\"SELECT cos_dist(%s, review_embedding) as dist, imdb_id from imdb_reviews_new111 order by {dist_calculation_format} limit 2;\", \n\u001b[0;32m---> 13\u001b[0;31m                         (embedding,embedding))\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/encodings/utf_8.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "find_similar_foreach(all_embeds, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 6.C: Vector Index + SQL JOIN (35seconds - 40x faster than above!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limitation of the above approach is that we are iterating over all movie reviews and issuing vector search operations. We can instead describe the full query to our database and have it return the final result - a list of review IDs and corresponding closest N review ids.\n",
    "\n",
    "The query in the block below does exactly that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = None\n",
    "with global_conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "SELECT\n",
    "  forall.imdb_id, \n",
    "  nearest_per_id.near_imdb_ids, nearest_per_id.imdb_dists\n",
    "FROM\n",
    "  (\n",
    "    SELECT\n",
    "      imdb_id, review_embedding\n",
    "    FROM\n",
    "      imdb_reviews_new111\n",
    "    LIMIT 100000\n",
    "  ) AS forall\n",
    "  JOIN LATERAL (\n",
    "    SELECT\n",
    "      ARRAY_AGG(imdb_id) AS near_imdb_ids, \n",
    "      ARRAY_AGG(imdb_dist) AS imdb_dists\n",
    "    FROM\n",
    "      (\n",
    "        SELECT\n",
    "          t2.imdb_id,\n",
    "          cos_dist(forall.review_embedding, t2.review_embedding) AS imdb_dist\n",
    "        FROM\n",
    "          imdb_reviews_new111 t2\n",
    "        ORDER BY\n",
    "          forall.review_embedding <-> t2.review_embedding\n",
    "        LIMIT\n",
    "          5\n",
    "      ) AS __unused_name\n",
    "  ) nearest_per_id ON TRUE\n",
    "ORDER BY\n",
    "  forall.imdb_id;\n",
    "\"\"\")\n",
    "    final_res = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What's going on in that query?__\n",
    "\n",
    "There are two main subuqeries in the qery above\n",
    "\n",
    "1. Subquery forall:\n",
    "This is the first building block of the query. It selects two pieces of information for each review in the dataset: the unique movie identifier (imdb_id) and the 'review embedding' (review_embedding). The review_embedding is a numerical representation of the review's content. This subquery is limited to the first 100,000 entries in the imdb_reviews_new1 table, indicating a focus on a specific portion of the dataset.\n",
    "\n",
    "\n",
    "2. Lateral Join Subquery nearest_per_id:\n",
    "The second building block is a more complex subquery that performs a lateral join. This means it takes each row from the forall subquery and finds the top 5 closest reviews to it based on the cosine distance between their embeddings. The cosine distance is a measure used to determine how similar two documents are in the context of natural language processing. This subquery aggregates the IDs (imdb_id) and distances (imdb_dist) of these closest reviews into arrays, essentially creating a list of most similar reviews for each review in the forall subset.\n",
    "\n",
    "__Relation of the Outer Query to Building Block Queries:__\n",
    "The outer query brings together these building blocks. It selects the imdb_id from the forall subquery and pairs it with the arrays of nearest imdb_ids and their corresponding distances (imdb_dists) from the nearest_per_id subquery. By joining these components, the query effectively maps each movie in the original subset to a list of movies with the most similar reviews, along with the degree of similarity. \n",
    "The final output is ordered by the imdb_id from the forall subset, providing an organized list of movies and their closest counterparts in terms of review content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_similar = [r for r in final_res if 0.01 < r[2][1] and r[2][1] <= 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>most_similar_imdb_ids</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1578</td>\n",
       "      <td>[1578, 18101, 18102, 18104, 23556]</td>\n",
       "      <td>[5.9604645e-08, 0.026409447, 0.08959967, 0.104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1772</td>\n",
       "      <td>[1772, 18172, 1767, 18166, 18165]</td>\n",
       "      <td>[0.0, 0.029390275, 0.058212996, 0.07342106, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1832</td>\n",
       "      <td>[1832, 18723, 18714, 18713, 18709]</td>\n",
       "      <td>[-1.1920929e-07, 0.026373267, 0.03368485, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6113</td>\n",
       "      <td>[6113, 6116, 5751, 2751, 3336]</td>\n",
       "      <td>[0.0, 0.025266469, 0.13563824, 0.15339321, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6116</td>\n",
       "      <td>[6116, 6113, 5751, 8140, 2751]</td>\n",
       "      <td>[-1.1920929e-07, 0.025266469, 0.15087664, 0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11802</td>\n",
       "      <td>[11802, 11803, 12036, 10494, 2901]</td>\n",
       "      <td>[0.0, 0.014384985, 0.12550741, 0.13626295, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11803</td>\n",
       "      <td>[11803, 11802, 12036, 10494, 2901]</td>\n",
       "      <td>[0.0, 0.014384985, 0.14396846, 0.15840888, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14384</td>\n",
       "      <td>[14384, 14396, 14397, 14387, 14388]</td>\n",
       "      <td>[-1.1920929e-07, 0.027822495, 0.07430953, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14396</td>\n",
       "      <td>[14396, 14384, 14387, 14388, 14397]</td>\n",
       "      <td>[-1.1920929e-07, 0.027822495, 0.05249983, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18101</td>\n",
       "      <td>[18101, 1578, 18102, 18104, 23556]</td>\n",
       "      <td>[0.0, 0.026409447, 0.08518565, 0.11065954, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18172</td>\n",
       "      <td>[18172, 1772, 1767, 18166, 18165]</td>\n",
       "      <td>[-1.1920929e-07, 0.029390275, 0.06425351, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18524</td>\n",
       "      <td>[18524, 18760, 18764, 18765, 18761]</td>\n",
       "      <td>[1.1920929e-07, 0.029762506, 0.046407104, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18723</td>\n",
       "      <td>[18723, 1832, 18714, 18713, 18709]</td>\n",
       "      <td>[0.0, 0.026373267, 0.036916196, 0.04617828, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18760</td>\n",
       "      <td>[18760, 18524, 18764, 18765, 18761]</td>\n",
       "      <td>[0.0, 0.029762506, 0.059289873, 0.06593734, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    imdb_id                most_similar_imdb_ids  \\\n",
       "0      1578   [1578, 18101, 18102, 18104, 23556]   \n",
       "1      1772    [1772, 18172, 1767, 18166, 18165]   \n",
       "2      1832   [1832, 18723, 18714, 18713, 18709]   \n",
       "3      6113       [6113, 6116, 5751, 2751, 3336]   \n",
       "4      6116       [6116, 6113, 5751, 8140, 2751]   \n",
       "5     11802   [11802, 11803, 12036, 10494, 2901]   \n",
       "6     11803   [11803, 11802, 12036, 10494, 2901]   \n",
       "7     14384  [14384, 14396, 14397, 14387, 14388]   \n",
       "8     14396  [14396, 14384, 14387, 14388, 14397]   \n",
       "9     18101   [18101, 1578, 18102, 18104, 23556]   \n",
       "10    18172    [18172, 1772, 1767, 18166, 18165]   \n",
       "11    18524  [18524, 18760, 18764, 18765, 18761]   \n",
       "12    18723   [18723, 1832, 18714, 18713, 18709]   \n",
       "13    18760  [18760, 18524, 18764, 18765, 18761]   \n",
       "\n",
       "                                             distance  \n",
       "0   [5.9604645e-08, 0.026409447, 0.08959967, 0.104...  \n",
       "1   [0.0, 0.029390275, 0.058212996, 0.07342106, 0....  \n",
       "2   [-1.1920929e-07, 0.026373267, 0.03368485, 0.04...  \n",
       "3   [0.0, 0.025266469, 0.13563824, 0.15339321, 0.1...  \n",
       "4   [-1.1920929e-07, 0.025266469, 0.15087664, 0.16...  \n",
       "5   [0.0, 0.014384985, 0.12550741, 0.13626295, 0.1...  \n",
       "6   [0.0, 0.014384985, 0.14396846, 0.15840888, 0.1...  \n",
       "7   [-1.1920929e-07, 0.027822495, 0.07430953, 0.07...  \n",
       "8   [-1.1920929e-07, 0.027822495, 0.05249983, 0.05...  \n",
       "9   [0.0, 0.026409447, 0.08518565, 0.11065954, 0.1...  \n",
       "10  [-1.1920929e-07, 0.029390275, 0.06425351, 0.07...  \n",
       "11  [1.1920929e-07, 0.029762506, 0.046407104, 0.05...  \n",
       "12  [0.0, 0.026373267, 0.036916196, 0.04617828, 0....  \n",
       "13  [0.0, 0.029762506, 0.059289873, 0.06593734, 0....  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(very_similar, columns=[\"imdb_id\", \"most_similar_imdb_ids\", \"distance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flag similar reviews\n",
    "#### Below are some example pairs of reviews marked as similar according to our filtering above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dogs go to Heaven is one of the best movies I've ever seen. I first saw it when I was like 3. Now I'm 12 and I rented it, it makes me think of things and it brings back so many memories, those were \"the days\". I love the music, I love when Charlie is arriving in Heaven, I love the song \"Let me be surprised\". I love how Charlie looks and his voice, Bert Reynolds could only play Charlie's voice this great. I love this movie, the 1st one is the best one because it's so original and great. It really does bring back memories that no one can describe, not even me. If only I could go back to those days. I love the characters. If this is the way the memories come back when I'm 12 imagine how I'll feel when I'm like 19, I hope I'll be able to watch this when I'm older. When I first seen this I never knew that I would really look back on it and feel this way , I hope it will be available to watch. I'm so happy that this movie was made and the amazing idea came to mind and heart. On a scale from 1-10 I'd give it a perfect 10. It's an amazing movie. It's so hard to explain the feeling, when I get older and if I have kids, I hope they can experience this feeling. \n",
      "__VS__\n",
      " \"May Contain Spoilers*<br /><br />\"All Dogs Go to Heaven\" is a great movie. I saw it in 1989 when I was two years old. I didn't understand it that well but as I saw it more and more times I started to love it. I love the songs in this movie. My favorite songs are \"Let Me Be Surprised\" and \"Soon You'll Come Home\". Those are beautiful songs. The only thing that bothers me about the movie is Charlie dieing. When I was little my sister couldn't even watch that part. Other than that this movie is wonderful. <br /><br />My favorite part of the movie is when Annabelle and Charlie are flying around heaven. Heaven is beautiful in the movie and the \"clocks\" are very clever. I also love Itchy, in fact I have 3 dachshunds of my own. They are so cute. <br /><br />Overall I love this movie and suggest everyone should see it. I give this movie 10/10 stars.\n"
     ]
    }
   ],
   "source": [
    "print(data[\"text\"][14384], \"\\n__VS__\\n\",data[\"text\"][14396])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This has to be the funniest stand up comedy I have ever seen. Eddie Izzard is a genius, he picks in Brits, Americans and everyone in between. His style is completely natural and completely hilarious. I doubt that anyone could sit through this and not laugh their a** off. Watch, enjoy, it's funny. \n",
      "__VS__\n",
      " This is another gem of a stand up show from Eddie Izzard . You cannot fail to laugh at the wide range of topics he talks about. He even takes the piss out of his American audiance at times and most of them didnt even realise it! A must see for anybody who likes comedians. 9 out of 10.\n"
     ]
    }
   ],
   "source": [
    "print(data[\"text\"][16401], \"\\n__VS__\\n\",data[\"text\"][16408])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus! Evaluate the quality of our approximate vector index\n",
    "Since we know for sure each vector must be closest to itself, we can use the clustering results to see how well our approximate index keeps this invariant. An exact vector index would always keep this invariant. HNSW sacrifices exactness for performance and it gives us 3 hyper-parameters to tune how close it tries to get to the exact index. Obviously, the more exact we make our approximate index, the slower it will become, so there is a tradeoff here.\n",
    "\n",
    "We can again use Lantern dashboard to create indexes with different parameters and see which one results in fewer mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = [r for r in final_res if r[0] not in r[1]]\n",
    "print(\"In %d (of %d reviews) the review in query was not considered close to itself by our index \" % (len(mistakes), len(final_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1082 (of 25000 reviews) the review in query was not considered close to itself by our index \n"
     ]
    }
   ],
   "source": [
    "mistakes = [r for r in final_res if r[0] not in r[1]]\n",
    "print(\"In %d (of %d reviews) the review in query was not considered close to itself by our index \" % (len(mistakes), len(final_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus! Flag Identical Reviews\n",
    "We can also use the query results from our index to find identical duplicate reviews in the dataset. To do this, we will search for vectors that are extremely close together and have different IMDB ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(167,\n",
       "  [167, 168, 5851, 13388, 24841],\n",
       "  [5.9604645e-08, 5.9604645e-08, 0.17264384, 0.17720449, 0.18217313]),\n",
       " (168,\n",
       "  [167, 168, 5851, 13388, 24841],\n",
       "  [5.9604645e-08, 5.9604645e-08, 0.17264384, 0.17720449, 0.18217313]),\n",
       " (194,\n",
       "  [194, 195, 5614, 13064, 14024],\n",
       "  [-1.1920929e-07, 0.0005583167, 0.141236, 0.17064029, 0.17728132]),\n",
       " (195,\n",
       "  [195, 194, 5614, 13064, 14024],\n",
       "  [-1.1920929e-07, 0.0005583167, 0.14078432, 0.17046922, 0.1763081]),\n",
       " (357,\n",
       "  [10274, 357, 13607, 13619, 13610],\n",
       "  [-1.1920929e-07, -1.1920929e-07, 0.11676812, 0.12345934, 0.13316357]),\n",
       " (358,\n",
       "  [10275, 358, 10222, 597, 5414],\n",
       "  [0.0, 0.0, 0.13878095, 0.14487368, 0.1503331]),\n",
       " (359,\n",
       "  [359, 10276, 4728, 22560, 3379],\n",
       "  [5.9604645e-08, 5.9604645e-08, 0.1301226, 0.1348725, 0.13509935]),\n",
       " (360,\n",
       "  [360, 10277, 6284, 1288, 15822],\n",
       "  [0.0, 0.0, 0.15350217, 0.15636468, 0.16078287]),\n",
       " (361,\n",
       "  [10278, 361, 13602, 13608, 13615],\n",
       "  [-1.1920929e-07, -1.1920929e-07, 0.13646817, 0.14160305, 0.14672083]),\n",
       " (599,\n",
       "  [599, 12001, 18952, 2206, 13494],\n",
       "  [5.9604645e-08, 5.9604645e-08, 0.11482328, 0.12670994, 0.12890428])]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identical = [r for r in final_res if r[2][1] < 0.01]\n",
    "identical[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see that there are many pairs of reviews that have very close to zero distance, This gives us very high confidence that the underlying reivews are identical Below are example identical rows, taken from the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What was an exciting and fairly original series by Fox has degraded down to meandering tripe. During the first season, Dark Angel was on my weekly \"must see\" list, and not just because of Jessica Alba.<br /><br />Unfortunately, the powers-that-be over at Fox decided that they needed to \"fine-tune\" the plotline. Within 3 episodes of the season opener, they had totally lost me as a viewer (not even to see Jessica Alba!). I found the new characters that were added in the second season to be too ridiculous and amateurish. The new plotlines were stretching the continuity and credibility of the show too thin. On one of the second season episodes, they even had Max sleeping and dreaming - where the first season stated she biologically couldn\\'t sleep.<br /><br />The moral of the story (the one that Hollywood never gets): If it works, don\\'t screw with it!<br /><br />azjazz'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"][357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What was an exciting and fairly original series by Fox has degraded down to meandering tripe. During the first season, Dark Angel was on my weekly \"must see\" list, and not just because of Jessica Alba.<br /><br />Unfortunately, the powers-that-be over at Fox decided that they needed to \"fine-tune\" the plotline. Within 3 episodes of the season opener, they had totally lost me as a viewer (not even to see Jessica Alba!). I found the new characters that were added in the second season to be too ridiculous and amateurish. The new plotlines were stretching the continuity and credibility of the show too thin. On one of the second season episodes, they even had Max sleeping and dreaming - where the first season stated she biologically couldn\\'t sleep.<br /><br />The moral of the story (the one that Hollywood never gets): If it works, don\\'t screw with it!<br /><br />azjazz'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"][10274]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
